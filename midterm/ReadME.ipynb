{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README FILE - MIDTERM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Enron data-set, perform 3 analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSIS 1 - Retriving email message text content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All the emails in ENRON dataset are traversed using os.walk()\n",
    "- Each email JSON file is loaded into another data structure.\n",
    "- This loaded file is analysed to find message text content and printing the email in tree format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##RESULT\n",
    "\n",
    "##We get the body of every email in an organised way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSIS 2 - Retriving all emailIds and their email subjects involved in Enron Dataset with their frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using os.walk() we traverse through uneven hierarchy and read each JSON file in the dataset.\n",
    "- While analysing a file we store data in string 'b' and then parse the data using an email parser.\n",
    "- With the help of parser we find all the to and from emailids and append it to a list 'list_tofrom'.\n",
    "- Then we use a funtion 'mainlist' to convert the 'list_tofrom' into dictionary 'Main' with counts of occurence of - -- each emailids\n",
    "- Also we track the various subject of these mails and their frequency.\n",
    "- All the retrieved data is stored in a csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## ANALYSIS 2 - Determining the sent mails, inbox, sent_items for each individual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By traversng through each folder and then respectively into it's files \n",
    "- we get the count of all the types of mails in a person's folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 2: \n",
    "# Use NYT API to collect NYT data. Perform 3 analysis on the collected data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLLECTING AND STORING DATA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generate key from the NYT API site\n",
    "- On console exported the key and assigned it to a variable\n",
    "- Using they generated, type of data is chosen from NYT API and filtered according to our requirements.\n",
    "- The url generated is copied from the site and assigned to a variable ‘url’  in jupiter notebook.\n",
    "- The data is requested and stored in list ‘response_data’ depending on the hits.\n",
    "- Then the data from the list in stored in JSON files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSIS 1 - Find out 100 most frequent words in the snippet of Archive Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DATA - NYT API -Article\n",
    "- DATE RANGE - 31st December 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With the help of nltk.corpus and regular expression top 100 most frequent words have been found.\n",
    "- The JSON files in Article_search folder is read one by one.\n",
    "- Data is determined using regular expression.\n",
    "- All the data are stored in a list 'Words'.\n",
    "- The data is then transformed by removing stopwords and punctuations to have only words.\n",
    "- The words are converted to lower case to avoid redundancy and determine each words counts.\n",
    "- Tha word and its count is stored in a dictionary.\n",
    "- The data in the dictionary is used to generate csv called 'Article.csv'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##RESULT\n",
    "##The most frequenctly used 100 words have been determined.\n",
    "##In this case the word 'new' is the most frequent word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSIS 2 - Graph Generation of article counts and storing data in csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DATA - NYT API -Archive\n",
    "- DATE RANGE - October Month 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this analysis the data used is for the OCtober month of 2016.\n",
    "- The date for each article in the each JSON file of Archive folder is considered.\n",
    "- The publish date of the article is trimmed to get the day part of the date to generate graph for \n",
    "- every date of October to count the articles that were publihed\n",
    "- The collected data is stored in a dictionary with count of article for a particular date.\n",
    "- Using the data graph is generated with the help of matplotlib.pyplot.\n",
    "- Also a csv Archive.csv is generated which contains news_desk,document_type,word_count,source & \n",
    "- pub_date information of each article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##RESULT\n",
    "##WE know on which day of OCtober month the number of article published."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSIS 3 - Traversing through nested Dictionaries and list and Storing data in CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DATA - NYT API -Books\n",
    "- DATE RANGE - 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The data from JSON files of Books folder is loaded and analyse one by one.\n",
    "- By traversing throught the nested dictionary and lists useful information about each book published is retrived\n",
    "- The data retrieved is stored in a Book.csv"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
